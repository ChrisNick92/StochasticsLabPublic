{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Στοχαστικές Διεργασίες και Βελτιστοποίηση στη Μηχανική Μάθηση\n",
    "\n",
    "## 10ο Εργαστήριο - *DNS Water Torture σε Recursive DNS Servers*\n",
    "\n",
    "- Ονομ/νυμο: Χρήστος Νίκου\n",
    "- AM: 03400146\n",
    "- Ιδιότητα: Μεταπτυχιακός φοιτητής Επιστήμης Δεδομένων και Μηχανικής Μάθησης (ΕΔΕΜΜ)\n",
    "- Ηλεκτρονική Διεύθυνση: christosnikou@mail.ntua.gr / chrisnick92@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLUCLr2dsyWQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab10/Lab_theory\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγειται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
    "\n",
    "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος www.ntua.gr είναι το <i>www</i>, ενώ το prefix του ονόματος dolly.netmode.ece.ntua.gr είναι το <i>dolly</i>.</p>\n",
    "\n",
    "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
    "\n",
    "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
    "<ul>\n",
    "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
    "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
    "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
    "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
    "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
    "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
    "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
    "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
    "</ul>\n",
    "\n",
    "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
    "<ul>\n",
    "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
    "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab10/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 1\n",
    "\n",
    ">*Ποια είναι η παραδοχή του αλγορίθμου <b>Naive Bayes Classifier</b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Η κύρια παραδοχή του αλγορίθμου <b>*Naive Bayes*</b> είναι ότι υποθέτει <b>ανεξαρτησία μεταξύ των χαρακτηριστικών</b> των δειγμάτων εκπαίδευσης. Πιο συγκεκριμένα, στο κλασικό πλαίσιο της επιβλεπόμενης ταξινόμησης υποθέτουμε έχουμε $C_1,\\dots,C_k$ διακεκριμένες κλάσεις και ένα σύνολο δειγμάτων $\\{(\\vec{x_i},y_i)\\}_{i=1}^{N}$ όπου τα $\\vec{x_i}$ είναι τα χαρακτηριστικά και $y_i$ οι ετικέτες που μας δείχνουν σε ποιό απ' τα $C_1,\\dots,C_k$ ανήκει το $\\vec{x_i}$. Συνήθως έχουμε ότι $y_i \\in\\{1,\\dots K\\}$, όπου αν $y_i=j$ τότε το χαρακτηριστικό $\\bf{x}$ είναι απ' την κλάση $1\\leq j\\leq K$. Τα διανύσματα $\\vec{x_i}$ αποτελούν τα χαρακτηριστικά που περιγράφουν τις κλάσεις $C_1,\\dots,C_k$. Η αναπαράσταση των $\\vec{x_i}$ γίνεται μέσω διανυσμάτων που ανήκουν στον χώρο $\\mathbb{R}^N$, όπου $N$ είναι το πλήθος των χαρακτηριστικών. Ο ταξινομητής του *Bayes* υποθέτει ότι κάθε συνιστώσα του διανύσματος $\\vec{x}=(x_1,\\dots,x_N)$ ακολουθεί μια (άγνωστη εν γένει) κατανομή. Ο τρόπος με τον οποίο αποφασίζει σε ποια κλάση θα ανήκει το άγνωστο δείγμα $\\vec{x}$ περιγράφεται απ' την σχέση<br>\n",
    "\n",
    "\\begin{align}\\tag{1.1}\n",
    "\\hat{y}&=\\text{argmax}_{1\\leq j\\leq K}\\mathbb{P}(C_j\\,|\\,\\vec{x}).\n",
    "\\end{align}\n",
    "<br>\n",
    "\n",
    "Χρησιμοποιώντας τον κανόνα του Bayes, η $(1.1)$ γράφεται<br>\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y}&=\\text{argmax}_{1\\leq j\\leq K}\\mathbb{P}(C_j\\,|\\,\\vec{x})\\\\\n",
    "&=\\text{argmax}_{1\\leq j\\leq K}\\frac{\\mathbb{P}(C_j)\\mathbb{P}(\\vec{x}\\,|\\,C_j)}{\\mathbb{P}(\\vec{x})}\\\\\n",
    "&=\\text{argmax}_{1\\leq j\\leq K}\\mathbb{P}(C_j)\\mathbb{P}(\\vec{x}\\,|\\,C_j)\\tag{1.2}.\n",
    "\\end{align}<br>\n",
    "\n",
    "Τώρα, παρατηρούμε ότι το γινόμενο που εμφανίζεται στην $(1.2)$ είναι ίσο με την από κοινού κατανομή $\\mathbb{P}(\\vec{X}=\\vec{x},C_j)=\\mathbb{P}(X_1 = x_1,\\dots,X_N=x_N,C_j)$, όπου $\\vec{X} =(X_1,\\dots,X_N)$ και κάθε $X_i$ είναι η τυχαία μεταβλητή του $i$-οστού χαρακτηριστικού. Εν γένει ο προσδιορισμός της πιθανότητας $\\mathbb{P}(\\vec{X}=\\vec{x},C_j)$ είναι δύσκολος. Σε αυτό το σημείο έρχεται η υπόθεση που κάνει ο αλγόριθμος *Naive Bayes* η οποία λέει ότι οι τυχαίες μεταβλητές $X_1,\\dots,X_N$ είναι <b> ανεξάρτητες</b>. Με άλλα λόγια ότι υπάρχει ανεξαρτησία μεταξύ των χαρακτηριστικών. Υποθέτοντας ότι οι $X_1,\\dots,X_N$ είναι ανεξάρτητες μπορούμε να γράψουμε<br>\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(\\vec{X}=\\vec{x},C_j)&= \\mathbb{P}(X_1=x_1,\\dots, X_N=x_N,C_j)\\\\\n",
    "&=\\mathbb{P}(X_N=x_N\\,|\\,X_1=x_1,\\dots X_{N-1}=x_{N-1},C_j)\\mathbb{P}(X_{N-1}=x_{N-1},\\dots,X_1=x_1,C_j)\\\\\n",
    "&\\mathbb{P}(X_N=x_N\\,|\\,C_j)\\cdot \\mathbb{P}(X_{N-1}=x_{N-1}\\,|\\,X_1=x_1,\\dots,X_{N-2}=x_{N-2},C_j)\\cdot \\mathbb{P}(X_1=x_1,\\dots,X_{N-2}=x_{N-2},C_j)\\\\\n",
    "&=\\mathbb{P}(X_N=x_N\\,|\\,C_j)\\cdot \\mathbb{P}(X_{N-1}=x_{N-1}\\,|\\,C_j)\\cdot \\mathbb{P}(X_1=x_1,\\dots,X_{N-2}=x_{N-2},C_j)\\\\\n",
    "&=\\dots = \\mathbb{P}(X_N=x_N\\,|\\,C_j)\\cdot \\mathbb{P}(X_{N-1}=x_{N-1}\\,|\\,C_j)\\cdot\\dots\\mathbb{P}(X_1=x_1\\,|\\,C_j)\\cdot \\mathbb{P}(C_j)\\\\\n",
    "&=\\prod_{i=1}^N\\mathbb{P}(x_i\\,|\\,C_j)\\cdot \\mathbb{P}(C_j),\n",
    "\\end{align}<br>\n",
    "\n",
    "όπου στην τελευταία ισότητα χρησιμοποιούμε καταχρηστικά τον συμβολισμό $\\mathbb{P}(X_i=x_i\\,|\\,C_j)=\\mathbb{P}(x_i\\,|\\,C_j)$. Το <b>πλεονέκτηα</b> αυτής της έκφρασης είναι ότι ο αλγόριθμος δε χρειάζεται πλέον να προσδιορίσει την πολυδιάστατη, και αρκετά πολύπλοκη, κατανομή $\\mathbb{P}(x_1,\\dots,x_N,C_j)$ παρά μόνον τις μονοδιάστατες κατανομές $\\mathbb{P}(x_i\\,|\\,C_j)$ για $1\\leq i \\leq N,\\, 1\\leq j \\leq K$ και την πιθανότητα $\\mathbb{P}(C_j)$, όπου $j=1,\\dots,K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 2\n",
    "\n",
    ">*Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b>Naive Bayes Classifier</b>.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Θεωρώντας ένα πρόβλημα ταξινόμησης, το ζητούμενο είναι η εύρεση της κατηγορίας, $y$, στην οποία ανήκει ένα δειγματικό σημείο, $\\mathbf{x} = \\left[x_1,x_2,\\dots,x_m\\right]^\\top$. Δεδομένης της προαναφερθείσας ανεξαρτησίας των χαρακτηριστικών, ο νόμος του Bayes για την posterior πιθανότητα $p\\left(y|\\mathbf{x}\\right)$ παίρνει τη μορφή<br>\n",
    "\n",
    "$$p\\left(y|\\mathbf{x}\\right) = \\frac{p\\left(\\mathbf{x}|y\\right)p\\left(y\\right)}{p\\left(\\mathbf{x}\\right)} = \\frac{p\\left(y\\right)}{p\\left(\\mathbf{x}\\right)}\\prod_{k=1}^{m}{p\\left(x_k|y\\right)}.$$\n",
    "\n",
    "Ο παρανομαστής στο τελευταίο σκέλος είναι ανεξάρτητος του $y$, συνεπώς για την ταξινόμηση ενός δειγματικού σημείου αρκεί κανείς να χρησιμοποιήσει μόνο τον αριθμητή:\n",
    "\n",
    "$$p\\left(y|\\mathbf{x}\\right) \\propto p\\left(y\\right)\\prod_{k=1}^{m}{p\\left(x_k|y\\right)}.$$\n",
    "\n",
    "Δεδομένης της ποσότητας αυτής, η πρόβλεψη του ταξινομητή για την κλάση στην οποία ανήκει το δειγματικό σημείο γίνεται βάσει του κανόνα απόφασης Maximum A Posteriori (MAP) που περιγράψαμε και στη σχέση $(1.2)$, δηλαδή την επιλογή εκείνης της τιμής του $y$ που μεγιστοποιεί την posterior πιθανότητα (η πιο πιθανή υπόθεση):\n",
    "\n",
    "$$ \\hat{y} = \\text{argmax}_{y}\\left[ p\\left(y\\right)\\prod_{k=1}^{m}p\\left(x_k|y\\right)\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 3\n",
    "\n",
    ">*Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab10/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Κοιτώντας τα δύο αρχεία *valid_training.txt* και *valid_training.txt* παρατηρούμε πως το αρχείο των έγκυρων *prefixes* αποτελείται από συμβολοσειρές οι οποίες είναι αναγνώσιμες από έναν άνθρωπο σε αντίθεση με το αρχείο *invalid_training.txt* στο οποίο οι συμβολοσειρές φαίνεται να έχουν παραχθεί με τυχαίο τρόπο χωρίς να μπορούν να αναγνωστούν από έναν άνθρωπο. Πιο συγκεκριμένα, μια λέξη η οποία είναι αναγνώσιμη από έναν άνθρωπο δε θα περιέχει για παράδειγμα πολλά συνεχόμενα σύμφωνα, όπως και πολλούς αριθμούς να παρεμβάλονται μεταξύ των γραμμάτων. Όπως βλέπουμε και στην επόμενη απάντηση, αυτά είναι κάποια απ' τα χαρακτηριστικά τα οποία λαμβάνει υπ' όψιν η συγκεκριμένη υλοποίηση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 4\n",
    "\n",
    ">*Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης καθορίζονται από τη συνάρτηση `handle_name`. Όπως βλέπουμε και στον κώδικα που δίνεται παρακάτω η συνάρτηση `handle_name` επιστρέφει το συνολικό μήκος του prefix (μεταβλητή `total_length`), το συνολικό αριθμό των ψηφίων που περιέχει το prefix (μεταβλητή `total_digits`), το μέγιστο μήκος της συνεχόμενης ακολουθίας που περιέχει ψηφία στο prefix (μεταβλητή `max_numeric_sequence`), το πλήθος των συμφώνων καθώς και το μήκος της μεγαλύτερης ακολουθίας συμφώνων που εμφανίζονται στο prefix (μεταβλητές `total_consonants`, `max_consonants_sequence`). Και τέλος, των αριθμών των φωνηέντων και το μήκος της μεγαλύτερης ακολουθίας συνεχόμενων φωνηέντων που εμφανίζονται στο prefix (μεταβλητές `total_vowels`, `max_vowels`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 5\n",
    "\n",
    ">*Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο test set για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του training set; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Για να καταγράψουμε τον χρόνο εκτέλεσης της εκπαίδευσης του αλγορίθμου χρησιμοποιούμε τη βιβλιοθήκη `time` και καταγράφουμε τον χρόνο που χρειάζεται να υπολογιστούν οι πιθανότητες στις δύο κλήσεις της συνάρτησης `calculate_probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O_plJQ1Z2i5M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The training size is equal to 1400000.\n",
      "- Training time: 22.62834644317627 sec(s).\n",
      "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
      "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n"
     ]
    }
   ],
   "source": [
    "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
    "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
    "\n",
    "def load_file(file_name):\n",
    "    fd = open(file_name, \"r\")\n",
    "    my_set = set()\n",
    "    for prefix in fd:\n",
    "        prefix = prefix.rstrip()\n",
    "        my_set.add(prefix)\n",
    "    return my_set\n",
    "\n",
    "def calculate_probabilities(dataset):\n",
    "    stats = dict()\n",
    "    for index in range(0, 7):\n",
    "        stats[index] = dict()\n",
    "    for prefix in dataset:\n",
    "        features = handle_name(prefix)\n",
    "        for index in range(0, 7):\n",
    "            try:\n",
    "                stats[index][features[index]] += 1\n",
    "            except:\n",
    "                stats[index][features[index]] = 1\n",
    "\n",
    "    dataset_size = len(dataset)    \n",
    "    for index in range(0, 7):\n",
    "        for key in stats[index]:\n",
    "            stats[index][key] /= dataset_size\n",
    "    return stats\n",
    "\n",
    "def handle_name(prefix):\n",
    "    total_length = len(prefix)\n",
    "    total_digits, max_numeric_sequence = numeric(prefix)\n",
    "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
    "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
    "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
    "\n",
    "def vowels(prefix):\n",
    "    total_vowels = 0\n",
    "    vowels_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
    "            total_vowels += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            vowels_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    vowels_sequence.append(current_sequence)\n",
    "    max_vowels_sequence = max(vowels_sequence)\n",
    "    return total_vowels, max_vowels_sequence\n",
    "\n",
    "def consonants(prefix):\n",
    "    total_consonants = 0\n",
    "    consonants_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
    "            total_consonants += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            consonants_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    consonants_sequence.append(current_sequence)\n",
    "    max_consonants_sequence = max(consonants_sequence)\n",
    "    return total_consonants, max_consonants_sequence\n",
    "\n",
    "def numeric(prefix):\n",
    "    total_digits = 0\n",
    "    numeric_sequence = list()\n",
    "    current_sequence = 0\n",
    "    for char in prefix:\n",
    "        if char.isdigit() == True:\n",
    "            total_digits += 1\n",
    "            current_sequence += 1\n",
    "        else:\n",
    "            numeric_sequence.append(current_sequence)\n",
    "            current_sequence = 0\n",
    "    numeric_sequence.append(current_sequence)\n",
    "    max_numeric_sequence = max(numeric_sequence)\n",
    "    return total_digits, max_numeric_sequence\n",
    "            \n",
    "def find_prob(prefix, stats, fd):\n",
    "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
    "    try:\n",
    "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
    "    except:\n",
    "        prob = 0\n",
    "        fd.write(prefix + \"\\n\")\n",
    "    return prob\n",
    "\n",
    "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
    "    misclassifications = 0\n",
    "    names_processed = 0\n",
    "    for prefix in test_set:\n",
    "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
    "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
    "        if valid_prob != 0 and invalid_prob != 0:\n",
    "            names_processed += 1\n",
    "            if category == \"valid\" and valid_prob < invalid_prob:\n",
    "                misclassifications += 1\n",
    "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
    "                misclassifications += 1\n",
    "    return misclassifications, names_processed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load valid names training set\n",
    "    valid_names_training = load_file(\"./valid_training.txt\")\n",
    "    # Load valid names test set\n",
    "    valid_names_test = load_file(\"./valid_test.txt\")\n",
    "    # Load invalid names training set\n",
    "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
    "    # Load invalid names test set\n",
    "    invalid_names_test = load_file(\"./invalid_test.txt\") \n",
    "    \n",
    "    print(f\"- The training size is equal to {len(valid_names_training)+len(invalid_names_training)}.\")\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    tic = time.time()\n",
    "\n",
    "    valid_stats = calculate_probabilities(valid_names_training)\n",
    "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
    "    tac = time.time()\n",
    "    print(f\"- Training time: {tac-tic} sec(s).\")\n",
    "\n",
    "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
    "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
    "\n",
    "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
    "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Όπως βλέπουμε και απ' την παραπάνω έξοδο το μέγεθος του `training set` αποτελείται από 1.400.000 συμβολοσειρές. Ο χρόνος εκτέλεσης της εκπαίδευσης διήρκησε περίπου 22.62 δευτερόλεπτα. Περίπου το 1.9% των έγκυρων ονομάτων ταξινομήθηκαν λανθασμένα ως μη έγκυρα, ενώ περίπου το 1.2% των μη έγκυρων ονομάτων ταξινομήθηκαν ως έγκυρα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 6 & 7\n",
    "\n",
    "><b>6.</b> Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: *problematic_valid.txt* και *problematic_invalid.txt*. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b>*Naive Bayes Classifier*</b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);<br>\n",
    "\n",
    "\n",
    "><b>7.</b> Μελετώντας τη συνάρτηση `find_prob`, θα δείτε πως λείπουν οι πιθανότητες `prior` από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις `prior` πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (`valid`, `invalid`) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<b>1.</b> Ο ρόλος των δύο αυτών αρχείων είναι η καταγραφή των συμβολοσειρών οι οποίες δημιουργούν το πρόβλημα που είναι γνωστό ως zero frequency problem (πρόβλημα μηδενικής συχνότητας) κατά τη χρήση του ταξινομητή Naive Bayes. Συγκεκριμένα, το πρόβλημα αυτό προκύπτει όταν ο αλγόριθμος καλείται να ταξινομήσει ένα δείγμα που δεν έχει συναντήσει κατά την εκπαίδευσή του σε μια από τις κατηγορίες και για το λόγο αυτό του προσδίδει μηδενική posterior πιθανότητα στην κατηγορία αυτή. Έτσι, ακόμη κι αν η posterior πιθανότητά του στην άλλη κατηγορία είναι πάρα πολύ μικρή, τελικά θα ταξινομηθεί (εσφαλμένα) σε αυτήν. Μία πιθανή λύση στο πρόβλημα αυτό είναι το λεγόμενο additive smoothing (γνωστό και ως Laplace smoothing), κατά το οποίο προστίθεται ένας αριθμός στην τελική posterior πιθανότητα όλων των δειγμάτων, ο οποίος είναι αντιστρόφως ανάλογος του πλήθους τους. Η διαδικασία αυτή έχει ορισμένες αναλογίες με την πρόσθεση πολύ μικρών αριθμών, π.χ.  $10^{-10}$ , σε αριθμούς που βρίσκονται σε παρανομαστές κλασμάτων, προκειμένου να εξασφαλίσουμε overflow errors σε υπολογισμούς που πραγματοποιεί μια μηχανή.\n",
    "\n",
    "\n",
    "<b>2.</b> Η παραδοχή που έχει γίνει για τις `prior` πιθανότητες είναι ότι αυτές οι δύο είναι ίσες. Δηλαδή, υπάρχει η πιθανότητα μια νέα ονομασία να ανήκει στις έγκυρες είναι 0.5 όπως το ίδιο ισχύει και για τις ονομασίες που ανήκουν στις ονομασίες των έγκυρων. Αυτή η υπόθεση είναι λογική αν λάβουμε υπ' όψιν το πλήθος των δειγμάτων ανά κατηγορία. Όπως βλέπουμε παρακάτω και για τις δύο κατηγορίες αυτό είναι το ίδιο και ίσο με 700.000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Valid names: 700000\n",
      "- Invalid names: 700000\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Valid names: {len(valid_names_training)}\")\n",
    "print(f\"- Invalid names: {len(invalid_names_training)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Υπάρχουν διάφορες εναλλακτικές για την εκτίμηση των prior πιθανοτήτων, μέσω αλγορίθμων και μεθόδων που εκτιμούν γενικά παραμέτρους στατιστικών κατανομών, δεδομένου ενός δειγματικού συνόλου. Ένα παράδειγμα τέτοιας μεθόδου είναι ο *Maximul Likelihood estimator (MLE)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ερώτηση 8\n",
    "\n",
    ">Μπορείτε να προτείνετε κάποιο επιπρόσθετο feature για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Κοιτώντας τα δύο αρχεία `valid_training.txt` και `invalid_training.txt` παρατηρούμε ότι οι λέξεις που περιέχονται στο αρχείο `invalid_training.txt` περιέχουν συνήθως περισσότερα διαφορετικά γράμματα απ' ότι στο αρχείο που αντιστοιχεί στις έγκυρες ονομασίες. Συνεπώς, ένα χαρακτηριστικό που θα μπορούσαμε να δοκιμάσουμε να χρησιμοποιήσουμε είναι το πλήθος των διαφορετικών συμβόλων που εμφανίζονται σε μια ονομασία."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_10_DNS_Water_Torture).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DGA_Classification_LSTM.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Στοχαστικές Διεργασίες και Βελτιστοποίηση στη Μηχανική Μάθηση\n",
    "\n",
    "## 12ο Εργαστήριο - *LSTM's - DGA Algorithm*\n",
    "\n",
    "- Ονομ/νυμο: Χρήστος Νίκου\n",
    "- AM: 03400146\n",
    "- Ιδιότητα: Μεταπτυχιακός φοιτητής Επιστήμης Δεδομένων και Μηχανικής Μάθησης (ΕΔΕΜΜ)\n",
    "- Ηλεκτρονική Διεύθυνση: christosnikou@mail.ntua.gr / chrisnick92@gmail.com"
   ],
   "metadata": {
    "id": "uu-gIZnRIYPy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Πρόσφατες επιθέσεις, όπως εκείνη στον πάροχο DNS Dyn (<a href=\"https://en.wikipedia.org/wiki/DDoS_attack_on_Dyn\">wiki</a>) αποδεικνύουν ότι ένα από τα σημαντικότερα προβλήματα που αντιμετωπίζει το σύγχρονο Διαδίκτυο είναι εκείνο των botnets. Σε αυτά, ένας επιτιθέμενος συγκεντρώνει την υπολογιστική ισχύ που του είναι απαραίτητη για την εκδήλωση επιθέσεων DDoS ή/και άλλων κακόβουλων δραστηριοτήτων εγκαθιστώντας λογισμικό σε μεγάλο πλήθος από υπολογιστές (bots) που έχουν κενά ασφαλείας (π.χ. συσκευές Internet of Things - IoT).\n",
    "\n",
    "Οι μολυσμένοι υπολογιστές (bots) διατηρούν διαύλους επικοινωνίας με το διαχειριστή του botnet (Command & Control Server) με σκοπό να λαμβάνουν εντολές και να αποστέλλουν πληροφορίες. Για το σκοπό αυτό εκμεταλλεύονται καθιερωμένα πρωτόκολλα, όπως το DNS με την παραγωγή μεγάλου πλήθους από domain names μέσω Domain Generation Algorithms (DGA's) που αλλάζουν διαρκώς για την επικοινωνία του bot με το διαχειριστή του, ώστε να αποφεύγεται ο εντοπισμός του Command & Control Server.\n",
    "\n",
    "Τα ονόματα DNS που χρησιμοποιούνται από αλγορίθμους DGA μπορεί να είναι είτε τυχαία αλφαριθμητικά (π.χ. asdfasjkdfh8oawher8has.com) ή συνδυασμοί τυχαίων λέξεων που έχουν ληφθεί από κάποιο λεξικό (π.χ. school-doctor.com). Χρησιμοποιείται ένας μεγάλος αριθμός από τέτοια ονόματα, η πλειοψηφία των οποίων δεν έχουν κάποια αντιστοίχιση σε διεύθυνση IP και στοχεύουν στην απόκρυψη του Command & Control Server, επειδή οι αμυνόμενοι καλούνται να ελέγξουν κάθε ένα από τα ονόματα που παρατηρούν στο δίκτυό τους, σπαταλώντας χρόνο και πόρους. Επιπρόσθετα, η διεύθυνση IP του Command & Control Server αλλάζει πολύ συχνά (πολλές φορές σε μία μέρα), ώστε να αποφεύγεται ο εντοπισμός του ακόμα και όταν εντοπίζονται τα ονόματα DGA που οδήγησαν σε αυτόν."
   ],
   "metadata": {
    "id": "RczVgvwwHX0h",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab12/dga.png\"></img>"
   ],
   "metadata": {
    "id": "XaN28mnKLHlO",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget https://raw.githubusercontent.com/ChrisNick92/StochasticsLabPublic/master/lab12/dga_domains_full.csv"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agMOqg9cqH65",
    "outputId": "5a7e1322-4bb7-4df8-c231-283b3a35f354",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-07-07 20:00:06--  https://raw.githubusercontent.com/ChrisNick92/StochasticsLabPublic/master/lab12/dga_domains_full.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19952823 (19M) [text/plain]\n",
      "Saving to: ‘dga_domains_full.csv’\n",
      "\n",
      "dga_domains_full.cs 100%[===================>]  19.03M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2022-07-07 20:00:06 (250 MB/s) - ‘dga_domains_full.csv’ saved [19952823/19952823]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"\"></img>"
   ],
   "metadata": {
    "id": "xvWLJ4gvJdx5",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def add_word_distinct_chars(string, distinct_chars):\n",
    "    for char in string:\n",
    "        distinct_chars.add(char)\n",
    "    return distinct_chars\n",
    "\n",
    "def find_max_len(string, max_len):\n",
    "    string_length = len(string)\n",
    "    if string_length > max_len:\n",
    "        max_len = string_length\n",
    "    return max_len\n",
    "\n",
    "def load_data(filename):\n",
    "    dataset = []\n",
    "    distinct_chars = set()\n",
    "    max_len = 0\n",
    "    currentIndex = 0\n",
    "    diverse_labels = dict()\n",
    "    with open(filename, \"r\") as fdr:\n",
    "        for line in fdr:\n",
    "            line = line.strip()\n",
    "            general, label, name = line.split(\",\")\n",
    "            name = name.split(\".\")[0]\n",
    "            if label not in diverse_labels.keys():\n",
    "                diverse_labels[label] = currentIndex\n",
    "                currentIndex += 1\n",
    "            distinct_chars = add_word_distinct_chars(name, distinct_chars)\n",
    "            max_len = find_max_len(name, max_len)\n",
    "            temp_list = []\n",
    "            temp_list.append(name)\n",
    "            temp_list.append(label)\n",
    "            dataset.append(temp_list)\n",
    "    random.shuffle(dataset)\n",
    "    return dataset, distinct_chars, max_len, diverse_labels\n",
    "\n",
    "def assign_index(chars):\n",
    "    features = {}\n",
    "    for index, char in enumerate(chars):\n",
    "        features[char] = index\n",
    "    return features\n",
    "\n",
    "def convert_dataset_and_tokenize(dataset, features, max_len):\n",
    "    for item_no, example in enumerate(dataset):\n",
    "        name = example[0]\n",
    "        label = example[1]\n",
    "        tokenized = []\n",
    "        padding_needed = max_len - len(name)\n",
    "        for index in range(padding_needed):\n",
    "            tokenized.append(0)\n",
    "        for char in name:\n",
    "            token = features[char]\n",
    "            tokenized.append(token)\n",
    "        example[0] = tokenized\n",
    "        dataset[item_no] = example\n",
    "    return dataset\n",
    "\n",
    "def split_examples_labels(dataset):\n",
    "    examples = [entry[0] for entry in dataset]\n",
    "    labels = [entry[1] for entry in dataset]\n",
    "    return examples, labels\n",
    "\n",
    "def convert_labels_to_int(labels, diverse_labels):\n",
    "    for index, label in enumerate(labels):\n",
    "        labels[index] = diverse_labels[label]\n",
    "    return labels\n",
    "\n",
    "def build_model(max_features, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length = max_len))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(26, activation = 'softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def return_fold(examples, labels_int, num_folds, current_fold):\n",
    "    interval = len(examples) // num_folds\n",
    "    current_start = (current_fold - 1) * interval\n",
    "    current_end = current_fold * interval\n",
    "    X_test = examples[current_start:current_end]\n",
    "    y_test = labels_int[current_start:current_end]\n",
    "    X_train = examples[:current_start]\n",
    "    y_train = labels_int[:current_start]\n",
    "    X_train.extend(examples[current_end:])\n",
    "    y_train.extend(labels_int[current_end:])\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def make_predictions(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = numpy.argmax(y_pred, axis = 1)\n",
    "    return y_pred\n",
    "\n",
    "def return_confusion_matrix(y_test, y_pred):\n",
    "    return confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def return_classification_report(y_test, y_pred, diverse_names):\n",
    "    target_names = []\n",
    "    for item in diverse_names.keys():\n",
    "        target_names.append(item)\n",
    "    print(classification_report(y_test, y_pred, target_names = target_names))\n",
    "    return None\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    dataset, distinct_chars, max_len, diverse_labels = load_data(\"dga_domains_full.csv\")\n",
    "    dataset = dataset[0:100000]\n",
    "    max_features = len(distinct_chars) + 1\n",
    "    features = assign_index(distinct_chars)\n",
    "    dataset = convert_dataset_and_tokenize(dataset, features, max_len)\n",
    "    examples, labels = split_examples_labels(dataset)\n",
    "    labels_int = convert_labels_to_int(labels, diverse_labels)\n",
    "\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    number_of_folds = 5\n",
    "    for fold in range(1, number_of_folds + 1):\n",
    "        X_train, y_train, X_test, y_test = return_fold(examples, labels_int, number_of_folds, fold)\n",
    "        model = build_model(max_features, max_len)\n",
    "        print(\"Training for fold: \", fold)\n",
    "        history = model.fit(X_train, y_train, batch_size = 128, epochs = 5, verbose = 1)\n",
    "        scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "        print(f'Score for fold {fold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        y_pred = make_predictions(model, X_test)\n",
    "        print(return_confusion_matrix(y_test, y_pred))\n",
    "        return_classification_report(y_test, y_pred, diverse_labels)\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('Average scores for all folds:')\n",
    "        print(f'> Accuracy: {numpy.mean(acc_per_fold)} (+- {numpy.std(acc_per_fold)})')\n",
    "        print(f'> Loss: {numpy.mean(loss_per_fold)}')\n",
    "        print('------------------------------------------------------------------------')\n"
   ],
   "metadata": {
    "id": "MJMvYAjMK2of",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e17dcb76-102d-44ba-f06b-cf1baf1cde0d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training for fold:  1\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 180s 284ms/step - loss: 1.4637 - accuracy: 0.6054\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 178s 284ms/step - loss: 0.9636 - accuracy: 0.7070\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 176s 281ms/step - loss: 0.8145 - accuracy: 0.7479\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 178s 285ms/step - loss: 0.7358 - accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.6662 - accuracy: 0.7873\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5682 - accuracy: 0.8171\n",
      "Score for fold 1: loss of 0.56817227602005; accuracy of 81.71499967575073%\n",
      "[[ 300    0  113    0    4    0    0    8    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0  376    0    0    0    0    2    0    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    0   16    0    1]\n",
      " [ 109    3 9637    6   65    6    7   40   33   20   33    5   21    1\n",
      "    59    6   11    1   23    0   31   21    1    1    6    0]\n",
      " [   0    0    5  329    0   26    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   19    1    0    0    0    0    0    0]\n",
      " [   0    0   82    0  277    0    0    0    0    0   18    0    0    0\n",
      "     0    1    0    0    0    0    6    0    0    0    0    0]\n",
      " [   0    0    4    0    0  375    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   13    1    0    0    0    0    0    0]\n",
      " [   0    0   18   25    1   19  118    0    0   30    2    0   44    8\n",
      "     0    2   22   15   54    0    0    2    0    0    0   25]\n",
      " [  12    0   27    0    0    0    0  363    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   87    0    9    0    0    0  273    0   13    0    1    0\n",
      "     0    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0   31    3    4    0    3    0    0  345    0    0    9    0\n",
      "     0    5    0    0    0    1    0    0    0    0    0    0]\n",
      " [   0    0   99    0    0    0    0    0    2    0  302    0    0    0\n",
      "     0    1    0    0    0    0   10    0    0    0    0    0]\n",
      " [   0    0    2    0    1    0    0    0    0    0    0  407    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   88    0    1    0    4    0    2   81    9    0  133    0\n",
      "     0   12   31    0    0    0    0   56    0    0    0    0]\n",
      " [   0    0   18   53    4   22    0    0    0   56    0    0   55   23\n",
      "     0    6   42    1   94    0    0    1    0    0    0   18]\n",
      " [   4    0  245    1    1    0    0    0    0    1    0    0    1    0\n",
      "   121    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0    0   45    0    0    0    0    0    0    1    3    0    3    1\n",
      "     0  307    2    0    0    0    0    5    0    0    0    0]\n",
      " [   0    1   10    0    2    0    0    0    0    5    0    0    3    0\n",
      "     0    2  354    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    3    1    0   25   21    0    0    0    0    0    0    0\n",
      "     0    0    1  297   52    0    0    0    0    0    0    7]\n",
      " [   0    0   13    0    4    1    0    0    0    1    0    0    0    0\n",
      "     0    4   97    2  266    1    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  394    0    0    0    0    0    0]\n",
      " [   0    0   21    0    0    0    0    0    0    2    0    0    2    0\n",
      "     0    0    0    0    0    0  356    0    0    0    0    0]\n",
      " [   0    0  194    0    1    0    0    0    1    5    7    0  107    1\n",
      "     0   14    1    0    0    0    0   70    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  393    0    0    0]\n",
      " [   0    1    1    0    0    0    2    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0  416    0    0]\n",
      " [   3    0  335    0    0    0    0    0    0    0    0    0    1    0\n",
      "     0    0    0    0    0    0    0    0    0    0   38    0]\n",
      " [   0    0   35   40    0   33    0    0    0   35    2    0   36   10\n",
      "     0    2   49    0   70    1    0    2    0    0    0   73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.70      0.71      0.70       425\n",
      "     corebot       0.99      0.95      0.97       397\n",
      "       alexa       0.87      0.95      0.91     10146\n",
      "     ranbyus       0.72      0.87      0.79       380\n",
      "       symmi       0.74      0.72      0.73       384\n",
      "      emotet       0.74      0.95      0.83       393\n",
      "    dircrypt       0.75      0.31      0.44       385\n",
      "      matsnu       0.88      0.90      0.89       402\n",
      "       simda       0.88      0.71      0.79       384\n",
      "      fobber       0.59      0.86      0.70       401\n",
      "      pushdo       0.78      0.73      0.75       414\n",
      "      qadars       0.99      0.99      0.99       410\n",
      "      kraken       0.32      0.32      0.32       417\n",
      "      ramnit       0.52      0.06      0.11       393\n",
      "      nymaim       0.67      0.32      0.44       375\n",
      "      pykspa       0.85      0.84      0.84       367\n",
      "       tinba       0.58      0.94      0.72       377\n",
      "     murofet       0.94      0.73      0.82       407\n",
      "cryptolocker       0.45      0.68      0.54       389\n",
      "       ramdo       0.99      1.00      0.99       394\n",
      "     vawtrak       0.88      0.93      0.91       381\n",
      "   conficker       0.45      0.17      0.25       401\n",
      "    padcrypt       1.00      1.00      1.00       393\n",
      "      rovnix       0.96      0.99      0.98       420\n",
      "    suppobox       0.84      0.10      0.18       377\n",
      "      necurs       0.59      0.19      0.29       388\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.76      0.69      0.69     20000\n",
      "weighted avg       0.81      0.82      0.79     20000\n",
      "\n",
      "Training for fold:  2\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 179s 284ms/step - loss: 1.4828 - accuracy: 0.6045\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 177s 283ms/step - loss: 0.9719 - accuracy: 0.7056\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 178s 285ms/step - loss: 0.8152 - accuracy: 0.7456\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 181s 290ms/step - loss: 0.7235 - accuracy: 0.7715\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.6672 - accuracy: 0.7883\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5903 - accuracy: 0.8085\n",
      "Score for fold 2: loss of 0.590287446975708; accuracy of 80.84999918937683%\n",
      "[[ 229    0  152    0    9    0    0    9    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    1]\n",
      " [   0  398    2    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    0    4    0    1]\n",
      " [  37    2 9588    3   51    6    2   66   26   20   35    3   16    1\n",
      "    54    8    5    1    7    1   17   41    0    0    4    1]\n",
      " [   1    0    7  359    1   12    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0   19    0    0    0    0    0    0    0]\n",
      " [   0    0  117    0  225    0    0    0    0    0   23    0    0    0\n",
      "     0    7    0    0    0    3    6    0    0    0    0    0]\n",
      " [   0    0   10    0    1  349    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1    9    0    0    0    1    0    0    0]\n",
      " [   0    0   22   10    0   13  119    0    1   52    1    0   31   16\n",
      "     0    6   24   11   45    0    0    6    0    0    0   16]\n",
      " [   7    0   23    0    0    0    0  372    0    0    0    0    0    0\n",
      "     1    0    0    2    0    0    0    0    0    0    0    0]\n",
      " [   0    0   99    0    0    0    0    0  264    0    5    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   47   11    3    0    2    0    0  334    0    0    8    1\n",
      "     0    3    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  126    0    0    0    0    0    1    0  298    0    0    0\n",
      "     0    2    0    0    0    0   10    0    0    0    0    0]\n",
      " [   0    0    6    0    0    0    0    0    0    0    0  393    0    0\n",
      "     0    2    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  103    0    0    0    4    0    5  120    3    0   88    6\n",
      "     0   10   12    0    0    0    0   64    0    0    0    0]\n",
      " [   0    0   41   33    4   32    2    0    0   64    0    0   35   31\n",
      "     0    2   37    3   86    0    0    3    1    0    0   23]\n",
      " [   5    0  277    0    1    0    0    0    0    0    0    0    2    0\n",
      "   122    0    0    0    0    0    0    1    0    0    0    0]\n",
      " [   0    0   44    0    2    0    0    0    4    4    5    0    3    0\n",
      "     0  317    0    0    0    0    0    6    0    0    0    0]\n",
      " [   0    0   12    0    1    0    0    0    0    7    0    0    1    5\n",
      "     0    1  351    0    1    0    0    0    0    0    0    0]\n",
      " [   0    0    9    0    0   29   23    0    0    0    0    0    0    0\n",
      "     0    1    2  310   39    1    0    0    0    0    0    6]\n",
      " [   0    0   24    0    0    5    0    0    0    2    0    1    0    0\n",
      "     0    4   83    5  299    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  399    0    0    0    0    0    0]\n",
      " [   0    0   42    0    0    0    0    0    0    0    0    0    3    0\n",
      "     0    0    0    0    0    0  356    0    0    0    0    0]\n",
      " [   0    0  180    0    1    0    0    0    3   28    1    0   76    4\n",
      "     0    8    0    0    0    0    0   97    0    0    0    0]\n",
      " [   0    0    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  390    0    0    0]\n",
      " [   0    1    0    0    0    0    3    0    0    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    0    0  396    0    0]\n",
      " [   0    0  402    0    3    0    0    0    2    0    1    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0   13    0]\n",
      " [   0    0   30   36    2   35    1    0    2   40    3    0   42   37\n",
      "     0    4   32    4   63    0    0    8    1    0    0   73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.82      0.57      0.67       400\n",
      "     corebot       0.99      0.98      0.99       407\n",
      "       alexa       0.84      0.96      0.90      9995\n",
      "     ranbyus       0.79      0.90      0.84       400\n",
      "       symmi       0.74      0.59      0.66       381\n",
      "      emotet       0.73      0.94      0.82       371\n",
      "    dircrypt       0.76      0.32      0.45       373\n",
      "      matsnu       0.83      0.92      0.87       405\n",
      "       simda       0.86      0.72      0.78       368\n",
      "      fobber       0.50      0.82      0.62       409\n",
      "      pushdo       0.79      0.68      0.73       437\n",
      "      qadars       0.99      0.98      0.98       401\n",
      "      kraken       0.29      0.21      0.24       415\n",
      "      ramnit       0.30      0.08      0.12       397\n",
      "      nymaim       0.69      0.30      0.42       408\n",
      "      pykspa       0.84      0.82      0.83       385\n",
      "       tinba       0.64      0.93      0.76       379\n",
      "     murofet       0.92      0.74      0.82       420\n",
      "cryptolocker       0.52      0.71      0.60       423\n",
      "       ramdo       0.99      1.00      0.99       399\n",
      "     vawtrak       0.91      0.89      0.90       401\n",
      "   conficker       0.43      0.24      0.31       398\n",
      "    padcrypt       0.99      1.00      0.99       391\n",
      "      rovnix       0.99      0.99      0.99       402\n",
      "    suppobox       0.76      0.03      0.06       422\n",
      "      necurs       0.60      0.18      0.27       413\n",
      "\n",
      "    accuracy                           0.81     20000\n",
      "   macro avg       0.75      0.67      0.68     20000\n",
      "weighted avg       0.80      0.81      0.78     20000\n",
      "\n",
      "Training for fold:  3\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 179s 284ms/step - loss: 1.4656 - accuracy: 0.6039\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 177s 284ms/step - loss: 0.9596 - accuracy: 0.7102\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 179s 286ms/step - loss: 0.8059 - accuracy: 0.7493\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 177s 283ms/step - loss: 0.7152 - accuracy: 0.7750\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 179s 286ms/step - loss: 0.6568 - accuracy: 0.7905\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.5641 - accuracy: 0.8175\n",
      "Score for fold 3: loss of 0.564148485660553; accuracy of 81.74999952316284%\n",
      "[[ 204    0  163    0    6    0    0    6    0    0    0    0    0    0\n",
      "     1    0    1    0    0    0    2    0    0    0    1    0]\n",
      " [   0  413    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    1]\n",
      " [  38    5 9662    8   45    3    3   22   39   13   30    4    6    4\n",
      "    34    6    7    1   19    0   56   56    0    0   18    1]\n",
      " [   0    0    9  353    2   22    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   18    0    0    0    0    0    0    0]\n",
      " [   2    0  114    0  256    0    0    0    1    0   11    0    0    0\n",
      "     0    0    0    0    0    0    6    0    0    0    0    0]\n",
      " [   0    0   10    0    0  380    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    8    1    0    0    0    0    0    0]\n",
      " [   0    0   16   18    3   19  115    0    1   48    0    0   32   18\n",
      "     0    2   22   12   46    0    0   13    0    0    0   24]\n",
      " [   7    0   49    0    0    0    0  347    0    0    0    0    0    0\n",
      "     2    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   78    0    1    0    0    0  309    0   12    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   34    0    5    0    2    0    1  320    0    0   10    1\n",
      "     0    9    0    0    0    0    3    1    0    0    0    0]\n",
      " [   0    0  106    0    2    0    0    0    1    0  264    0    0    0\n",
      "     0    0    0    0    0    0    9    0    0    0    0    0]\n",
      " [   0    0    2    0    0    0    0    0    0    0    0  384    0    0\n",
      "     0    4    2    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   93    0    1    0    3    0    1   87    0    0   76    5\n",
      "     0    9   18    0    3    0    0   91    0    0    0    2]\n",
      " [   0    0   33   40    2   18    0    0    0   33    1    0   37   37\n",
      "     0    5   36    0   92    1    0    9    0    0    0   28]\n",
      " [   1    0  289    1    0    0    0    0    0    0    0    0    0    0\n",
      "   138    0    0    0    0    0    2    0    0    0    1    0]\n",
      " [   0    0   44    0    4    0    0    0    6    0    2    0    0    0\n",
      "     0  330    0    0    1    0    0   16    0    0    0    0]\n",
      " [   0    0   13    0    1    0    0    0    0   10    0    0    1    1\n",
      "     0    1  337    0    2    0    0    0    0    0    0    0]\n",
      " [   0    0    6    0    0   39   26    0    0    0    0    0    0    0\n",
      "     0    0    3  269   40    0    0    0    0    0    0    4]\n",
      " [   0    0   16    0    2    1    0    0    0    5    0    1    0    0\n",
      "     0    3   74    0  282    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  417    0    0    0    0    0    0]\n",
      " [   0    0   15    0    0    0    0    0    0    1    0    0    2    0\n",
      "     0    0    0    0    0    0  408    1    0    0    0    0]\n",
      " [   0    0  190    0    1    0    0    0    5    0    1    0   48    2\n",
      "     0    6    0    0    0    0    0  157    0    0    0    0]\n",
      " [   0    0    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  406    0    0    0]\n",
      " [   0    0    1    1    0    0    1    0    0    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    0    0  386    0    0]\n",
      " [   0    0  387    0    0    0    0    0    3    1    0    0    0    0\n",
      "     0    0    0    0    0    0    3    0    0    0   25    0]\n",
      " [   0    0   37   30    4   24    0    0    1   30    1    0   26   24\n",
      "     0    3   28    1   66    0    0   20    0    0    0   75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.81      0.53      0.64       384\n",
      "     corebot       0.99      1.00      0.99       414\n",
      "       alexa       0.85      0.96      0.90     10080\n",
      "     ranbyus       0.78      0.87      0.83       404\n",
      "       symmi       0.76      0.66      0.71       390\n",
      "      emotet       0.75      0.95      0.84       399\n",
      "    dircrypt       0.77      0.30      0.43       389\n",
      "      matsnu       0.93      0.86      0.89       405\n",
      "       simda       0.84      0.77      0.80       400\n",
      "      fobber       0.58      0.83      0.69       386\n",
      "      pushdo       0.82      0.69      0.75       382\n",
      "      qadars       0.99      0.98      0.98       392\n",
      "      kraken       0.32      0.20      0.24       389\n",
      "      ramnit       0.39      0.10      0.16       372\n",
      "      nymaim       0.79      0.32      0.45       432\n",
      "      pykspa       0.87      0.82      0.85       403\n",
      "       tinba       0.64      0.92      0.75       366\n",
      "     murofet       0.95      0.70      0.80       387\n",
      "cryptolocker       0.49      0.73      0.59       384\n",
      "       ramdo       1.00      1.00      1.00       418\n",
      "     vawtrak       0.83      0.96      0.89       427\n",
      "   conficker       0.43      0.38      0.41       410\n",
      "    padcrypt       1.00      1.00      1.00       407\n",
      "      rovnix       1.00      0.99      0.99       391\n",
      "    suppobox       0.56      0.06      0.11       419\n",
      "      necurs       0.56      0.20      0.30       370\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.76      0.68      0.69     20000\n",
      "weighted avg       0.80      0.82      0.79     20000\n",
      "\n",
      "Training for fold:  4\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 180s 286ms/step - loss: 1.4787 - accuracy: 0.6031\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 179s 286ms/step - loss: 0.9686 - accuracy: 0.7053\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 180s 287ms/step - loss: 0.8151 - accuracy: 0.7509\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 178s 286ms/step - loss: 0.7273 - accuracy: 0.7721\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 180s 287ms/step - loss: 0.6721 - accuracy: 0.7880\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.5967 - accuracy: 0.8032\n",
      "Score for fold 4: loss of 0.596717119216919; accuracy of 80.32000064849854%\n",
      "[[ 244    0  133    0    5    0    0   14    0    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    0    0    0    1]\n",
      " [   0  390    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  62    1 9664    4   29    4    2   63   12   19   20    3    2    0\n",
      "    20    1   11    0    7    0   17   35    0    2    1    0]\n",
      " [   1    0   11  371    0   16    0    0    0    0    0    0    0    0\n",
      "     0    0    0    2   12    1    0    0    0    0    0    0]\n",
      " [   2    0  144    0  249    0    0    0    0    0   25    0    0    0\n",
      "     0    1    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0    4   10    1  350    0    0    0    0    0    0    0    0\n",
      "     0    2    0    1   11    1    0    0    0    0    0    0]\n",
      " [   0    0   29   12    0   24   91    0    0   52    0    0   27    7\n",
      "     0    1   27   19   44    0    0    1    0    0    0   37]\n",
      " [   6    0   20    0    0    0    0  329    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  128    0    1    0    0    0  252    0    8    0    0    0\n",
      "     0    1    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   37    0    1    0    1    0    1  366    0    0    0    0\n",
      "     0    2    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0  135    0    0    0    0    0    1    0  267    0    0    0\n",
      "     0    0    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0    0    2    0    1    0    1    0    0    0    0  435    0    0\n",
      "     0    0    2    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  117    0    1    0   10    0    1  109    1    0   67    1\n",
      "     0    7   38    0    0    0    0   54    0    0    0    0]\n",
      " [   0    0   43   42    0   49    0    0    0   47    1    0   26   16\n",
      "     0    5   67    2   84    0    0    1    0    0    0   58]\n",
      " [   9    0  323    0    1    0    0    1    0    1    0    0    0    0\n",
      "    66    0    1    0    0    0    0    3    0    0    0    0]\n",
      " [   0    0   48    0    0    0    0    0    1    2    2    0    2    0\n",
      "     0  324    1    0    0    0    1   16    0    0    0    0]\n",
      " [   0    0   20    0    1    0    0    0    0    1    0    1    0    0\n",
      "     0    4  373    0   10    0    0    0    0    0    0    0]\n",
      " [   0    0    6    0    1   34    8    4    0    0    0    0    0    0\n",
      "     0    0    2  320   29    0    0    0    0    0    0    3]\n",
      " [   0    0   28    0    3   28    0    0    0    0    0    0    0    0\n",
      "     0    2   88   19  222    0    0    0    1    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  379    0    0    0    0    0    0]\n",
      " [   0    0   79    0    0    0    0    0    1    2    0    0    2    0\n",
      "     0    0    0    0    0    0  329    1    0    0    0    0]\n",
      " [   0    0  216    0    0    0    0    0    4   45    1    0   70    0\n",
      "     0    7    0    0    0    0    1   97    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  368    0    0    0]\n",
      " [   0   13    0    0    0    0    1    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0    0  379    0    2]\n",
      " [   0    0  361    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0   31    0]\n",
      " [   1    0   51   19    3   29    0    0    2   40    2    0   20    8\n",
      "     0    3   34   14   68    0    0   14    0    0    0   85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.75      0.61      0.67       399\n",
      "     corebot       0.97      1.00      0.98       391\n",
      "       alexa       0.83      0.97      0.90      9979\n",
      "     ranbyus       0.81      0.90      0.85       414\n",
      "       symmi       0.84      0.59      0.69       422\n",
      "      emotet       0.66      0.92      0.77       380\n",
      "    dircrypt       0.80      0.25      0.38       371\n",
      "      matsnu       0.80      0.93      0.86       355\n",
      "       simda       0.92      0.65      0.76       390\n",
      "      fobber       0.54      0.89      0.67       409\n",
      "      pushdo       0.82      0.66      0.73       407\n",
      "      qadars       0.99      0.99      0.99       441\n",
      "      kraken       0.31      0.17      0.22       406\n",
      "      ramnit       0.48      0.04      0.07       441\n",
      "      nymaim       0.77      0.16      0.27       405\n",
      "      pykspa       0.90      0.82      0.86       397\n",
      "       tinba       0.58      0.91      0.71       410\n",
      "     murofet       0.85      0.79      0.82       407\n",
      "cryptolocker       0.45      0.57      0.50       391\n",
      "       ramdo       0.99      1.00      1.00       379\n",
      "     vawtrak       0.93      0.79      0.86       414\n",
      "   conficker       0.44      0.22      0.29       441\n",
      "    padcrypt       1.00      1.00      1.00       368\n",
      "      rovnix       0.99      0.96      0.98       396\n",
      "    suppobox       0.97      0.08      0.15       394\n",
      "      necurs       0.46      0.22      0.29       393\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.76      0.66      0.66     20000\n",
      "weighted avg       0.79      0.80      0.77     20000\n",
      "\n",
      "Training for fold:  5\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 180s 286ms/step - loss: 1.4888 - accuracy: 0.6021\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 180s 288ms/step - loss: 0.9716 - accuracy: 0.7068\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 179s 286ms/step - loss: 0.8201 - accuracy: 0.7469\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 181s 289ms/step - loss: 0.7274 - accuracy: 0.7693\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 179s 286ms/step - loss: 0.6622 - accuracy: 0.7895\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.5915 - accuracy: 0.8065\n",
      "Score for fold 5: loss of 0.5914892554283142; accuracy of 80.64500093460083%\n",
      "[[ 200    0  182    0    2    0    0   19    0    0    0    0    0    0\n",
      "     1    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0  410    2    0    0    0    1    0    0    0    0    0    0    0\n",
      "     0    0    0    1    1    0    0    0    0    2    0    1]\n",
      " [  29    3 9596    1   16    2    2   55   31   10   27    1   10    1\n",
      "    28    9    5    2   12    1   30   47    1    1    3    2]\n",
      " [   0    0   21  343    0   13    1    0    0    0    0    0    0    0\n",
      "     0    0    0    0   13    0    0    0    0    0    0    0]\n",
      " [   4    0  165    0  205    0    0    0    1    0   34    0    0    0\n",
      "     0    1    0    0    0    0    2    0    0    0    0    0]\n",
      " [   0    0   11    3    1  339    0    0    0    0    0    0    0    0\n",
      "     0    0    0   19    8    0    0    0    0    0    0    0]\n",
      " [   0    0   33   26    2   20  103    0    0   44    1    0   27    7\n",
      "     0    5   27   15   39    0    0   15    0    0    0   39]\n",
      " [   1    0   18    0    0    0    0  398    0    0    0    0    0    0\n",
      "     0    0    0    1    0    0    0    0    0    0    0    0]\n",
      " [   0    0   92    0    2    0    0    0  298    0    9    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   47    0    2    0    3    0    0  331    0    0    2    0\n",
      "     0    7    0    0    0    0    0    1    0    0    0    0]\n",
      " [   0    0  132    0    0    0    0    0    2    0  254    0    0    0\n",
      "     0    2    0    0    0    0    6    0    0    0    0    0]\n",
      " [   0    0    6    0    0    0    0    0    0    0    0  406    0    0\n",
      "     0    4    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0  109    0    2    0    4    0    0  118    7    0   62    7\n",
      "     0   10   10    0    1    0    0   78    0    0    0    0]\n",
      " [   0    0   38   36    1   43   14    0    0   38    1    0   28   19\n",
      "     0    6   49    3   82    0    0   10    0    0    0   47]\n",
      " [   2    0  301    0    0    0    1    1    0    1    0    0    1    0\n",
      "    97    0    1    0    0    0    1    1    0    0    0    0]\n",
      " [   0    0   46    0    0    0    0    0    0    1    2    0    1    0\n",
      "     0  339    1    0    0    0    0    2    0    0    0    0]\n",
      " [   0    0   25    0    2    0    0    0    0   15    0    0    0    1\n",
      "     0    3  383    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    2    0    1   23   22    0    0    0    0    0    0    0\n",
      "     0    0    1  327   21    0    0    0    0    0    0    3]\n",
      " [   0    0   28    0    4   12    2    0    0    3    0    0    0    0\n",
      "     0    1   76   18  239    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  385    0    0    0    0    0    0]\n",
      " [   0    0   45    0    0    0    0    0    0    2    0    0    1    0\n",
      "     0    0    0    0    0    0  372    0    0    0    0    0]\n",
      " [   0    0  182    0    1    0    0    0    0   13    0    0   40    4\n",
      "     0   10    0    0    0    0    1  144    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0  389    0    0    0]\n",
      " [   0    0    1    0    0    0    4    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0  397    0    2]\n",
      " [   1    0  375    0    0    0    0    1    0    0    1    0    0    0\n",
      "     0    0    0    0    0    0    1    0    0    0   25    0]\n",
      " [   0    0   55   30    1   22    7    0    1   48    3    0   16   10\n",
      "     0    3   30   16   79    0    1   21    0    0    0   68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gozi       0.84      0.50      0.62       404\n",
      "     corebot       0.99      0.98      0.99       418\n",
      "       alexa       0.83      0.97      0.90      9925\n",
      "     ranbyus       0.78      0.88      0.83       391\n",
      "       symmi       0.85      0.50      0.63       412\n",
      "      emotet       0.72      0.89      0.79       381\n",
      "    dircrypt       0.63      0.26      0.36       403\n",
      "      matsnu       0.84      0.95      0.89       418\n",
      "       simda       0.89      0.74      0.81       401\n",
      "      fobber       0.53      0.84      0.65       393\n",
      "      pushdo       0.75      0.64      0.69       396\n",
      "      qadars       1.00      0.98      0.99       416\n",
      "      kraken       0.33      0.15      0.21       408\n",
      "      ramnit       0.39      0.05      0.08       415\n",
      "      nymaim       0.77      0.24      0.36       407\n",
      "      pykspa       0.85      0.86      0.86       392\n",
      "       tinba       0.66      0.89      0.76       429\n",
      "     murofet       0.81      0.82      0.82       400\n",
      "cryptolocker       0.48      0.62      0.54       383\n",
      "       ramdo       1.00      1.00      1.00       385\n",
      "     vawtrak       0.90      0.89      0.89       420\n",
      "   conficker       0.45      0.36      0.40       395\n",
      "    padcrypt       1.00      1.00      1.00       389\n",
      "      rovnix       0.99      0.98      0.99       404\n",
      "    suppobox       0.89      0.06      0.12       404\n",
      "      necurs       0.42      0.17      0.24       411\n",
      "\n",
      "    accuracy                           0.81     20000\n",
      "   macro avg       0.75      0.66      0.67     20000\n",
      "weighted avg       0.79      0.81      0.78     20000\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.56817227602005 - Accuracy: 81.71499967575073%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.05599999427795 (+- 0.577748651566889)\n",
      "> Loss: 0.5821629166603088\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.590287446975708 - Accuracy: 80.84999918937683%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.05599999427795 (+- 0.577748651566889)\n",
      "> Loss: 0.5821629166603088\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.564148485660553 - Accuracy: 81.74999952316284%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.05599999427795 (+- 0.577748651566889)\n",
      "> Loss: 0.5821629166603088\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.596717119216919 - Accuracy: 80.32000064849854%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.05599999427795 (+- 0.577748651566889)\n",
      "> Loss: 0.5821629166603088\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.5914892554283142 - Accuracy: 80.64500093460083%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.05599999427795 (+- 0.577748651566889)\n",
      "> Loss: 0.5821629166603088\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ο παραπάνω κώδικας επιλύει το πρόβλημα της ταξινόμησης ονομάτων DNS ως προς το αν αυτά τα ονόματα είναι καλόβουλα ή έχουν παραχθεί από Domain Generation Algorithms (DGA's). Συγκεκριμένα, ο κώδικας επιλύει ένα πρόβλημα multi-class classification, όπου τα ονόματα αντιστοιχίζονται είτε στην κατηγορία alexa, εάν είναι καλόβουλα ή στην αντίστοιχα κατηγορία malware στην οποία ανήκουν. Το μοντέλο που έχει χρησιμοποιηθεί για την ταξινόμηση των ονομάτων είναι το LSTM, ενώ για το κατάλληλο validation του μοντέλου έχει χρησιμοποιηθεί η μέθοδος K-fold cross validation με Κ = 5. Τα δεδομένα εκπαίδευσης και αξιολόγησης έχουν ληφθεί από <a href=\"https://github.com/chrmor/DGA_domains_dataset\">εδώ</a> και χρησιμοποιούνται τα πρώτα 100000 ονόματα του αρχείου \"dga_domains_full.csv\". \n",
    "\n",
    "Μελετώντας τον κώδικα και εκτελώντας τον, να απαντήσετε στις ακόλουθες ερωτήσεις:\n",
    "<ul>\n",
    "<li>Γιατί το LSTM είναι κατάλληλο μοντέλο για την επίλυση του συγκεκριμένου προβλήματος;</li>\"\n",
    "<li>Τι είναι η λίστα ονομάτων Alexa (<a href=\"https://en.wikipedia.org/wiki/Alexa_Internet\">info</a>), ονόματα της οποίας έχουν χρησιμοποιηθεί για την κατηγορία των καλόβουλων ονομάτων;</li>\n",
    "<li>Να διαλέξετε δύο οικογένειες malware από την κατηγορία dga, δηλαδή την κατηγορία με τα κακόβουλα ονόματα που αντιστοιχούν σε malware. Να αναζητήσετε τι προβλήματα δημιουργούν τα malware αυτά, π.χ. υποκλοπή τραπεζικών κωδικών, έναρξη επιθέσεων DDoS, κλπ.</li>\n",
    "<li>Να περιγράψετε σύντομα τα βήματα που ακολουθεί το παραπάνω πρόγραμμα για την επίλυση του προβλήματος.</li>\n",
    "<li>Ποιος είναι ο ρόλος του embedding layer και τι παραμέτρους δέχεται;</li>\n",
    "<li>Να αναφέρετε λόγους για τους οποίους χρησιμοποιείται η μέθοδος K-fold cross validation.</li>\n",
    "<li>Κατά τη χρήση της μεθόδου K-fold cross validation, ανά fold, να αναφέρετε πόσα examples χρησιμοποιούνται για την εκπαίδευση του μοντέλου και πόσα για το validation/testing.\n",
    "<li>Δείτε <a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">εδώ</a> μεθόδους που μπορεί να χρησιμοποιούν έναντι της μεθόδου K-fold cross validation. Να αναφέρετε μερικά πλεονεκτήματα και μειονεκτήματά τους.</li>\n",
    "<li>Να αναλύσετε τα κριτήρια precision, recall και F1-score που εμφανίζονται στο classification report.</li>\n",
    "<li>Σε ποιες κατηγορίες πετυχαίνουμε καλύτερα αποτελέσματα και σε ποιες χειρότερα; Γιατί πιστεύετε ότι παίρνουμε αυτά τα αποτελέσματα;</li>\n",
    "</ul>"
   ],
   "metadata": {
    "id": "MZNG1h91eQwn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Απαντήσεις"
   ],
   "metadata": {
    "id": "c2yXVAPaIL2z",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 1\n",
    "\n",
    ">*Γιατί το LSTM είναι κατάλληλο μοντέλο για την επίλυση του συγκεκριμένου προβλήματος;*"
   ],
   "metadata": {
    "id": "FUTmyoWpIQD6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Στο συγκεκριμένο πρόβλημα τα ονόματα των ιστοσελίδων μπορούν να θεωρηθούν ως μια ακολουθία χαρακτήρων. Συνεπώς, η αρχιτεκτονική του *LSTM* είναι η ιδανική για προβλήματα όπου τα δεδομένα εισόδου έχουν ακολουθιακή συμπεριφορά. Όπως βλέπουμε και στα παρακάτω παραδείγματα φαίνεται να υπάρχει κάποια συσχέτιση μεταξύ των λέξεων και γραμμάτων που εμφανίζονται στα ονόματα που προέρχονται από καλόβουλες ιστοσελίδες."
   ],
   "metadata": {
    "id": "4aRlOfj7IV0M",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset, distinct_chars, max_len, diverse_labels = load_data(\"dga_domains_full.csv\")\n",
    "for i,sample in enumerate(dataset[:10]):\n",
    "  print(f\"- Sample:{i+1}{5*' '}domain name:{sample[0]}{5*' '}Type:{sample[1]}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvnuT6bqS4z5",
    "outputId": "ffed4eb8-5076-4073-db9a-7b84ae099599",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- Sample:1     domain name:glstvqjcdvhy     Type:necurs\n",
      "- Sample:2     domain name:fatlockcloudlineclubdiscount     Type:matsnu\n",
      "- Sample:3     domain name:i65l58m49a57gqiufriyatl48itfzcvezkycz     Type:murofet\n",
      "- Sample:4     domain name:y6sh14wbcfwxev3baxmd367     Type:corebot\n",
      "- Sample:5     domain name:kirdehei     Type:pushdo\n",
      "- Sample:6     domain name:mrunal     Type:alexa\n",
      "- Sample:7     domain name:justifacts     Type:alexa\n",
      "- Sample:8     domain name:e8u4u0ysm0m0     Type:qadars\n",
      "- Sample:9     domain name:plgswdcmvvmpclkko     Type:ranbyus\n",
      "- Sample:10     domain name:familijny     Type:alexa\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Όπως βλέπουμε τα ονόματα που αντιστοιχούν σε καλόβουλες ιστοσελίδες (alexa) μπορούν να αναγνωστούν από έναν άνθρωπο σε αντίθεση με τα ονόματα που αντιστοιχούν σε κακόβουλες ιστοσελίδες. Έτσι, μια αρχιτεκτονική *LSTM* θα μπορέσει να αποκωδικοποιήσει αυτή τη συσχέτιση που υπάρχει μεταξύ των ονομάτων και να διακρίνει τις διαφορετικές κατηγορίες. Επίσης, όπως φαίνεται και παρακάτω υπάρχουν λέξεις που περιέχουν εως και 64 γράμματα πράγμα το οποίο σημαίνει ότι μπορεί να υπάρχει εξάρτηση μεταξύ των γραμματών για μεγάλα χρονικά διαστήματα εντός της ακολουθίας. Έτσι, ένα *LSTM* με τις επιπλέον πύλες (*gates*) που διαθέτει θα μπορέσει να διατηρήσει τη χρήσιμη πληροφορία για μεγαλύτερα χρονικά βήματα αφαιρώντας όλη την πληροφορία που δεν χρειάζεται."
   ],
   "metadata": {
    "id": "3ypOgUMBUCxw",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"- Longest name has {max_len} words.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_3kaEZQTiT5",
    "outputId": "8937280b-de9d-4059-889e-f69f6c5c47f7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- Longest name has 63 words.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 2\n",
    "\n",
    ">*Τι είναι η λίστα ονομάτων Alexa (<a href=\"https://en.wikipedia.org/wiki/Alexa_Internet\">info</a>), ονόματα της οποίας έχουν χρησιμοποιηθεί για την κατηγορία των καλόβουλων ονομάτων;*"
   ],
   "metadata": {
    "id": "vs2iqf3yVO3X",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Η λίστα ονομάτων *Alexa* οφείλεται στην εταιρεία *Alexa Internet Inc.* η οποία ήταν Αμερικάνικη εταιρεία που ασχολούνταν με την ανάλυση αναζήτησης ιστοσελίδων στο διαδίκτυο (*web traffic analysis*). Από το έτος ίδρυσης της 1996 εώς και το 1999 η εταιρεία λειτουργούσε ως αυτόνομη εταιρεία ενώ μετά το 1999 αγοράστηκε απ' την *Amazon*. Η εταιρεία αρχικά μέσω μιας εργαλειοθήκης που διέθετε έδινε προτάσεις στους χρήστες της για το ποιες ιστοσελίδες να επισκεφθούν ανάλογα με τα ενδιαφεροντά τους. Τέλος, λόγω του μεγάλου χρηστών που εξυπηρετούσε διέθετε έναν μεγάλο όγκο δεδομένων σχετικά με το ποιες ιστοσελίδες προτιμούσαν να επισκέφτονται οι χρήστες και έτσι μπορούσε να διεξάγει σημαντικές έρευνες για τις προτιμήσεις των χρηστών."
   ],
   "metadata": {
    "id": "G-hnqoXZVUoP",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 3\n",
    "\n",
    ">*Να διαλέξετε δύο οικογένειες malware από την κατηγορία dga, δηλαδή την κατηγορία με τα κακόβουλα ονόματα που αντιστοιχούν σε malware. Να αναζητήσετε τι προβλήματα δημιουργούν τα malware αυτά, π.χ. υποκλοπή τραπεζικών κωδικών, έναρξη επιθέσεων DDoS, κλπ.*"
   ],
   "metadata": {
    "id": "ZmXO0yiLbHA_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Παρακάτω βλέπουμε τις διάφορες κατηγορίες των *malware* που υπάρχουν στο *csv* αρχείο."
   ],
   "metadata": {
    "id": "0sdjODNXb7e-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "classes = set()\n",
    "for sample in dataset:\n",
    "  if sample[1] != \"alexa\":\n",
    "    classes.add(sample[1])"
   ],
   "metadata": {
    "id": "Dkp9jdN3VMuo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "classes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0ftPYjXbhGP",
    "outputId": "a3a679ba-fed0-41e9-9a8a-993909108229",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conficker',\n",
       " 'corebot',\n",
       " 'cryptolocker',\n",
       " 'dircrypt',\n",
       " 'emotet',\n",
       " 'fobber',\n",
       " 'gozi',\n",
       " 'kraken',\n",
       " 'matsnu',\n",
       " 'murofet',\n",
       " 'necurs',\n",
       " 'nymaim',\n",
       " 'padcrypt',\n",
       " 'pushdo',\n",
       " 'pykspa',\n",
       " 'qadars',\n",
       " 'ramdo',\n",
       " 'ramnit',\n",
       " 'ranbyus',\n",
       " 'rovnix',\n",
       " 'simda',\n",
       " 'suppobox',\n",
       " 'symmi',\n",
       " 'tinba',\n",
       " 'vawtrak'}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- <b>Cryptolocker:</b> Το *cryptolocker* είναι ένα είδος ιού τύπου *ransomware* ο οποίος κρυπτογραφεί διάφορους φακέλους στον υπολογιστή που έχει εγκατασταθεί και για την αποκρυπτογράφησή τους ζητά από τους χρήστες κάποια πληρωμή έτσι ώστε να αποκτήσουν ξανά πρόσβαση στους μολυσμένους φακέλους. Κατά τη διάρκεια μιας *cryptolocker* επίθεσης ο ιός φτάνει στον υπολογιστή μέσω ενός *e-mail* ή κάποιου *spam* μηνύματος το οποίο περιέχει επιβλαβλή αρχεία ή κάποιο *link* σε μια επιβλαβλής ιστοσελίδα. Όταν ανοιχτεί το αρχείο ο ιός κρυπτογραφεί ένα μεγάλο μέρος των τοπικών φακέλων του υπολογιστή ζητώντας πληρωμή ως αντάλλαγμα για την αποκρυπτογράφηση των φακέλων."
   ],
   "metadata": {
    "id": "P2ZUeBHEdkUv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- <b> Symmi: </b>Ο *symmi* είναι ένας είδος ιού τύπου *trojan*. Ο *symmi* περνάει μέσα στον υπολογιστή μέσω ενός μολυσμένου φακέλου ο οποίος μπορεί να έχει βρεθεί στον υπολογιστή με διάφορους τρόπους (π.χ. email, spam messages, links κτλ). Ο ιός αυτός μπορεί να παίξει τον ρόλο του διαμεσολαβητή για την εγκατάσταση άλλων ιών. Παρ'όλα αυτά, ένας τέτοιος ιός μπορεί τραβήξει *screenshots* την επιφάνεια εργασίας του κάθε χρήστη, να καταγράψει τις λέξεις που πατήθηκαν μέσω του πληκτρολογίου, να αντιγράψει κωδικούς και να ελέγξει την κάμερα του υπολογιστή."
   ],
   "metadata": {
    "id": "9_U_ff0xoSb7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 4\n",
    "\n",
    ">*Να περιγράψετε σύντομα τα βήματα που ακολουθεί το παραπάνω πρόγραμμα για την επίλυση του προβλήματος.*"
   ],
   "metadata": {
    "id": "2FVVY387ukkS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Η εκτέλεση του προγράμματος ξεκινάει στο σημείο που ορίζεται η `main`. Αρχικά μέσω της συνάρτησης `load_data` γίνεται η ανάγνωση του αρχείου *csv* και διαμορφώνονται τα δεδομένα. Η συνάρτηση επιστρέφει μια λίστα που περιέχει το όνομα κάθε σελίδας αλλά και την κατηγορία της σελίδας. Επίσης, επιστρέφει το πλήθος των διαφορετικών χαρακτήρων που εμφανίζονται αλλά και το μήκος της μεγαλύτερης ονομασίας. Εν συνεχεία, μέσω της συνάρτησης `assign_index` γίνεται η αντιστοίχιση των μοναδικών χαρακτήρων σε αριθμούς. Ύστερα, μέσω της συνάρτησης `convert_dataset_and_tokenize` γίνεται η μετατροπή της κάθε ονομασίας σε ένα διάνυσμα που περιέχει τους αριθμούς του κάθε γράμματος που εμφανίζεται στην ονομασία. Επίσης, στην αρχή αυτού του διανύσματος προστίθενται μηδενικά μέχρις ότου το διάνυσμα να φτάσει τη διάσταση του διανύσματος που αντιστοιχεί στη μεγαλύτερη λέξη (64 στο συγκεκριμένο παράδειγμα). Μετά χωρίζονται τα labels από τα features και αρχικοποιείται το μοντέλο τύπου *LSTM*. Η διαδικασία του training έχει ως εξής: Το dataset χωρίζεται σε 5 ισοπληθή κομμάτια και καθένα απ'τα 5 κομμάτια παίζει το ρόλο του συνόλου επικύρωσης. Σε κάθε επανάληψη το μοντέλο εκπαιδεύεται στα 4 κομμάτια του dataset για 5 εποχές και αξιολογείται η επίδοσή του στο σύνολο επικύρωσης."
   ],
   "metadata": {
    "id": "mj_wqIRDuqj6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 5\n",
    "\n",
    ">*Ποιος είναι ο ρόλος του embedding layer και τι παραμέτρους δέχεται;*"
   ],
   "metadata": {
    "id": "P7DumLpk-QB-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ο ρόλος του *embedding layer* είναι να μετατρέψει τα διανύσματα ακεραίων που δημιουργήθηκαν μέσω της συνάρτησης `convert_dataset_and_tokenize` σε διανύσματα πραγματικών αριθμών αφήνοντας στον σχεδιαστή τη δυνατότητα να επιλέξει τη διάσταση αυτών των διανυσμάτων. Επίσης, με τον τρόπο που λειτουργεί το *embedding layer* τείνει να απεικονίζει λέξεις που έχουν παρόμοια σημασιολογική σε αριθμούς που απέχουν μικρή απόσταση μεταξύ τους κάτι το οποίο δεν συνέβαινε με την αναπαράσταση που είχαμε προηγουμένως. Οι παράμετροι που δέχεται είναι: 1) το πλήθος των διαφορετικών χαρακτηριστικών που έχουμε στο συγκεκριμένο πρόβλημα (`max_features`), το μέγεθος της διάστασης που θέλουμε να απεικονιστούν τα διανύσματα (128 στην περίπτωσή μας) και τέλος το μέγεθος των γραμμάτων που περιέχει η μεγαλύτερη λέξη (`max_len`)."
   ],
   "metadata": {
    "id": "pZ0IPgx9-V_-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 6\n",
    "\n",
    ">*Να αναφέρετε λόγους για τους οποίους χρησιμοποιείται η μέθοδος K-fold cross validation.*"
   ],
   "metadata": {
    "id": "7vId0EMoklhN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Η μέθοδος του *K-fold cross validation* χρησιμοποιείται έτσι ώστε να αποφεχθεί το *overfitting* του μοντέλου πάνω στα δεδομένα εκπαίδευσης. Αυτό συμβαίνει διότι το μοντέλο εκπαιδεύεται σε διαφορετικά μέρη του συνόλου δεδομένων με αποτέλεσμα να μην του επιτρέπεται να απομνημονεύσει ποτέ τον θόρυβο που υπάρχει στα δεδομένα. Ένας άλλος εξίσου σημαντικός λόγος είναι ότι η μέθοδος του *K-fold cross validation* δίνει την δυνατότητα στον σχεδιαστή να αξιολογήσει με μεγαλύτερη ακρίβεια τη γενίκευση του μοντέλου και αυτό διότι κάθε υποσύνολο του συνόλου δεδομένων αποτελεί ένα σύνολο επικύρωσης και έτσι η τελική αξιολόγηση του μοντέλου προκύπτει από ένα όσο το δυνατόν πιο ποικιλόμορφο σύνολο δεδομένων γίνεται."
   ],
   "metadata": {
    "id": "HMVR6DtPkoU1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 7\n",
    "\n",
    ">*Κατά τη χρήση της μεθόδου K-fold cross validation, ανά fold, να αναφέρετε πόσα examples χρησιμοποιούνται για την εκπαίδευση του μοντέλου και πόσα για το validation/testing.*"
   ],
   "metadata": {
    "id": "DWCWQiunpkak",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Όπως φαίνεται και παρακατώ το αρχικό dataset αποτελείται από 100000 δείγματα επομένως κατά τη διάρκεια μιας επανάληψης του *cross validation* χρησιμοποιούνται 80000 δείγματα για την εκπαιδεύση και τα υπόλοιπα 20000 για το validation/testing."
   ],
   "metadata": {
    "id": "vwK8g0C5qxzb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDw0mqiKqxLT",
    "outputId": "fe81d74a-565b-4a30-b047-544ebdbf38c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "674898"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 8\n",
    "\n",
    ">*Δείτε <a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">εδώ</a> μεθόδους που μπορεί να χρησιμοποιούν έναντι της μεθόδου K-fold cross validation. Να αναφέρετε μερικά πλεονεκτήματα και μειονεκτήματά τους.*"
   ],
   "metadata": {
    "id": "sSG_x2HPpm_c",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Μερικές εναλλακτικές μέθοδοι έναντι του *K-fold cross validation* είναι οι εξής:<br>\n",
    "\n",
    "<b>*Exhaustive cross-validation methods*</b>\n",
    "\n",
    "- <b>*Leave-p-out cross-validation:*</b> Αυτή η μέθοδος χρησιμοποιεί $p$ το πλήθος παρατηρήσεις απ' το σύνολο των δεδομένων για το σύνολο επικύρωσης και τις υπόλοιπες για το σύνολο εκπαίδευσης. Η διαδικασία αυτή επαναλαμβάνεται για όλους τους πιθανούς συνδυασμούς *p* στοιχείων που μπορούν να δημιουργηθούν. Το πλεονέκτημα αυτής της μεθόδου είναι ότι θα ελεγχθεί το μοντέλο πάνω σε πολλά διαφορετικά σύνολα δεδομένων. Το μειονέκτημα της μεθόδου είναι ότι για μεγάλο πλήθος δεδομένων η μέθοδος μπορεί να μην είναι υλοποιήσιμη εξαιτίας του μεγάλου υπολογιστικού κόστους.\n",
    "<br>\n",
    "\n",
    "- <b>*Leave-one-out cross-validation:*</b> Η μέθοδος αυτή αντιστοιχεί με την *leave-p-out cross-validation* όπου $p=1$. Δηλαδή, σε κάθε επανάληψη αντί το μοντέλο να εξετάζεται σε $p>1$ το πλήθος στοιχεία εξετάζεται μόνο σε 1. Η μέθοδος αυτή απαιτεί μικρότερο αριθμό επαναλήψεων απ'ότι η *leave-one-out cross-validation*, παρ'όλα αυτά για μεγάλο το πλήθος δείγμα μπορεί να απαιτεί και αυτή αρκετό χρόνο.\n",
    "<br>\n",
    "\n",
    "<b>*Non-exhaustive cross-validation methods*</b><br>\n",
    "\n",
    "Στις *non-exhaustive* cross-validation μεθόδους δεν χρειάζεται να υπολογιστούν όλοι οι πιθανοί συνδυασμοί που προκύπτουν απ' το σύνολο των δεδομένων. Σε αυτές τις μεθόδους ανήκει και η *K-fold cross-validation*.<br>\n",
    "\n",
    "- <b>*Holdout method:*</b> Στη μέθοδο *Holdout* κάθε σημείο του συνόλου δεδομένων αντιστοιχίζεται σε ένα απ' τα δύο σύνολα $d_1,d_2$. Το $d_1$ αντιστοιχεί στο σύνολο εκπαίδευσης ενώ το $d_2$ στο σύνολο επικύρωσης. Συνήθως, το μέγεθος του *train set* είναι μικρότερο του συνόλου εκπαίδευσης. Ένα μειονέκτημα αυτής της μεθόδου είναι ότι μπορεί, ανάλογα με το πως θα διαμεριστεί το σύνολο των δεδομένων, να δώσει μη ρεαλιστικά αποτελέσματα.<br>\n",
    "\n",
    "- <b>*Repeated random sub-sampling validation:*</b> Η μέθοδος αυτή είναι γνωστή και ως *Monte Carlo*. Αυτή η μέθοδος δημιουργεί τυχαία υποσύνολα του συνόλου δεδομένων καθένα απ'τα οποία χωρίζεται περαιτέρω σε σύνολο εκπαίδευσης και σύνολο επικύρωσης. Σε κάθε τέτοιο σύνολο το μοντέλο προσαρμόζεται στο σύνολο εκπαίδευσης και αξιολογείται στο σύνολο επικύρωσης. Η τελική ακρίβεια προκύπτει απ' τον μέσο όρο των επιμέρους αποτελεσμάτων. Το αποτέλεσμα αυτής της μεθόδου είναι ότι το η αναλογία του μεγέθους μεταξύ του *train* και του *test* set δεν εξαρτάται απ' τον αριθμό των επαναλήψεων. Το μειονέκτημα της μεθόδου είναι ότι μερικές παρατηρήσεις μπορεί να μην βρεθούν ποτέ στο σύνολο επικύρωσης ενώ άλλες μπορεί να βρεθούν παραπάνω από μια φορά."
   ],
   "metadata": {
    "id": "VvVuQ4U_8X4A",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 9\n",
    "\n",
    ">*Να αναλύσετε τα κριτήρια precision, recall και F1-score που εμφανίζονται στο classification report.*"
   ],
   "metadata": {
    "id": "NcQhrgmpKzKg",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Για τα παρακάτω υποθέτουμε ότι έχουμε ένα πρόβλημα κατηγοριοποίησης $N$ κλάσεων. Για κάθε $1\\leq i\\leq N$, με $\\text{TP}_i,\\, \\text{FP}_i,\\, \\text{TN}_i,\\, \\text{FN}_{i}$ συμβολίζουμε τα *true positive, false positive, true negative* και *false negative* της κλάσης $i$, αντιστοίχως.<br>\n",
    "\n",
    "- <b>Precision:</b> Το *precision* για μια κλάση $i$ δίνεται μέσω της σχέσης<br>\n",
    "\n",
    "$$\\text{Precision}_i = \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FP}_i},$$\n",
    "\n",
    "<br> και εκφράζει το ποσοστό των σωστών προβλέψεων που έγιναν για την κλάση $i$ προς όλες τις προβλέψεις που έγιναν για την κλάση $i$.\n",
    "\n",
    "- <b>Recall:</b> Το *recall* δίνεται μέσω της σχέσης<br>\n",
    "\n",
    "$$\\text{Recall}_{i} = \\frac{\\text{TP}_i}{\\text{TP}_i + \\text{FN}_i},$$\n",
    "\n",
    "<br> και εκφράζει το ποσοστό των σωστών προβλέψεων που έγιναν για την κλάση $i$.\n",
    "\n",
    "- <b>F1-score:</b> Το F1-score συνδυάζει συγχρόνως και το *precision* και το *recall* σε μια ποσότητα μέσω του αρμονικού μέσου<br>\n",
    "\n",
    "$$\\text{F1-score}_i = 2\\cdot \\frac{\\text{Precision}_i \\cdot \\text{Recall}_i}{\\text{Precision}_i + \\text{Recall}_i}.$$\n"
   ],
   "metadata": {
    "id": "bJkYgEbpK6AW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ερώτηση 10\n",
    "\n",
    ">*Σε ποιες κατηγορίες πετυχαίνουμε καλύτερα αποτελέσματα και σε ποιες χειρότερα; Γιατί πιστεύετε ότι παίρνουμε αυτά τα αποτελέσματα;*"
   ],
   "metadata": {
    "id": "m51djKhyPdNV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Όπως βλέπουμε και από τα classification report οι κατηγορίες στις οποίες το μοντέλο πετυχαίνει καλύτερα αποτελέσματα είναι οι: Alexa, qadars, corebot, rambo, padcrypt και rovnix. Ενώ τα χειρότερα αποτελέσματα στις: dircrypt, fobben, kraken, ramnit και necurs. Τα αποτελέσματα αυτά μπορεί να οφείλονται σε διάφορους λόγους, για παράδειγμα στην περίπτωση της κατηγορίας alexa όπως βλέπουμε το support της είναι δυσανάλογο σε σχέση με τις υπόλοιπες κατηγορίες με αποτέλεσμα ο αλγόριθμος να μαθαίνει αρκετά καλά αυτή την κατηγορία."
   ],
   "metadata": {
    "id": "Yub5JXj1PgrV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}
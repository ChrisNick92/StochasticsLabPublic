{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Στοχαστικές Διεργασίες και Βελτιστοποίηση στη Μηχανική Μάθηση\n",
    "\n",
    "## 1ο Εργαστήριο - Logistic Regression\n",
    "\n",
    "- Ονομ/νυμο: Χρήστος Νίκου\n",
    "- AM: 03400146\n",
    "- Ιδιότητα: Μεταπτυχιακός φοιτητής Επιστήμης Δεδομένων και Μηχανικής Μάθησης (ΕΔΕΜΜ)\n",
    "- Ηλεκτρονική Διεύθυνση: christosnikou@mail.ntua.gr / chrisnick92@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBURy4ihEfMj"
   },
   "source": [
    "<h1><b>Ο αλγόριθμος Logistic Regression</b></h1>\n",
    "\n",
    "# Εκφώνηση \n",
    "\n",
    "<p align=\"justify\">Στην άσκηση αυτή θα μελετήσετε τον αλγόριθμο <i>logistic regression</i>, κατασκευάζοντας ένα σύντομο πρόγραμμα. Στην άσκηση αυτή θα χρησιμοποιήσετε τη βιβλιοθήκη της <i>Python Scikit-Learn</i>. Για τη διευκόλυνσή σας παρέχονται οι δηλώσεις των βιβλιοθηκών που θα χρησιμοποιήσετε καθώς και εντολές με κενά. Συγκεκριμένα, θα κατασκευάσετε έναν <i>ταξινομητή Spam μηνυμάτων SMS</i>. Τα δεδομένα που θα χρησιμοποιήσετε για την εκπαίδευση και την επικύρωση του μοντέλου, καθώς και πληροφορίες για αυτά μπορούν να βρεθούν <a href=\"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\"><i>εδώ</i></a>.</p>\n",
    "<p align=\"justify\">Καλείστε να αναπτύξετε ένα πρόγραμμα, το οποίο:</p>\n",
    "<ul>\n",
    "<li>Θα φορτώνει τα δεδομένα από το αρχείο <i>.csv</i>.</li>\n",
    "<li>Θα διαχωρίζει με τυχαίο τρόπο τα δεδομένα που παρέχονται σε δεδομένα εκπαίδευσης <i>(training set)</i> και δεδομένα για τον υπολογισμό της ακρίβειας του μοντέλου <i>(test set)</i>.</li>\n",
    "<li>Θα πραγματοποιεί προεπεξεργασία στα δεδομένα χρησιμοποιώντας τη μέθοδο <i>TfidVectorizer</i> της βιβλιοθήκης <i>Scikit-Learn</i>. Περισσότερες πληροφορίες για τη μέθοδο <i>TfidVectorizer</i>, που περιλαμβάνεται στις δηλώσεις του προγράμματος, μπορούν να βρεθούν <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\"><i>εδώ</i></a>. Να σημειωθεί πως η μέθοδος <i>TfidVectorizer</i> της <i>Scikit-Learn</i> αφαιρεί και τα σημεία στίξης, καθώς επεξεργάζεται το dataset.</li>\n",
    "<li>Θα εκπαιδεύει το μοντέλο <i>logistic regression</i>.\n",
    "<li>Θα υπολογίζει την ακρίβειά του πάνω στο <i>test set</i>.</li>\n",
    "</ul>\n",
    "<p align=\"justify\">Για ποιους λόγους πιστεύετε ότι δεν είναι κατάλληλη η εφαρμογή της μεθόδου <i>linear regression</i> στο συγκεκριμένο πρόβλημα;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Απαντήσεις"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα 1\n",
    "\n",
    "> *Φορτώστε τα δεδομένα από το αρχείο .csv από το παρακάτω [link](#https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω κατεβάζουμε το αρχείο .csv και το διαβάζουμε με τη βιβλιοθήκη *pandas*. Παρακάτω βλέπουμε το DataFrame των δεδομένων, επίσης, μετατρέπουμε τα δεδομένα σε *numpy arrays*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEdw5TJMEmpy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-03-15 10:47:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 203415 (199K) [application/x-httpd-php]\n",
      "Saving to: 'smsspamcollection.zip.6'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 25% 20.7K 7s\n",
      "    50K .......... .......... .......... .......... .......... 50%  128K 3s\n",
      "   100K .......... .......... .......... .......... .......... 75% 71.0K 1s\n",
      "   150K .......... .......... .......... .......... ........  100% 65.0K=4.3s\n",
      "\n",
      "2022-03-15 10:47:32 (46.7 KB/s) - 'smsspamcollection.zip.6' saved [203415/203415]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "file_name = 'smsspamcollection.zip'\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extract('SMSSpamCollection')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path = 'SMSSpamCollection'\n",
    "df = pd.read_csv(path, sep='\\t', header = None)\n",
    "features, labels = df.iloc[:,1].to_numpy(), df.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως βλέπουμε το σύνολο δεδομένων αποτελείται από 5572 γραμμές και 2 στήλες. Η μια στήλη του συνόλου δεδομένων αντιστοιχεί στα σε γραπτά μηνύματα SMS και η δεύτερη στήλη του συνόλου δεδομένων φέρει την ένδειξη αν το το εν λόγω μήνυμα είναι SPAM ή HAM. Σκοπός μας είναι να αναπτύξουμε έναν ταξινομητή λογιστικής παλινδρόμησης που να κατηγοροποιεί τα μηνύματα σε SPAM και HAM. Το πρώτο που πρέπει να κάνουμε πριν αναπτύξουμε τον ταξινομητή είναι να φέρουμε το σύνολο δεδομένων σε κατάλληλη μορφή ώστε να είναι συμβατή με τις βιβλιοθήκες του *Scikit - learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "y = le.transform(labels)\n",
    "X = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως βλέπουμε παρακάτω μέσω της συνάρτησης *LabelEncoder* έχουμε αντιστοιχίσει τα *labels (ham & spam)* στις τιμές 0 και 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The true labels are: [0 0 1 ... 0 0 0]\n",
      "- And the transformed labels are: ['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "print(f\"- The true labels are: {y}\")\n",
    "print(f\"- And the transformed labels are: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα 2\n",
    "\n",
    "> *Διαχωρίστε με τυχαίο τρόπο τα δεδομένα που παρέχονται σε δεδομένα εκπαίδευσης (training set) και δεδομένα για τον υπολογισμό της ακρίβειας του μοντέλου (test set).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σε αυτό το σημείο χρησιμοποιώντας τη συνάρτηση *train_test_split* της βιβλιοθήκης *scikit-learn* διαχωρίζουμε το σύνολο των δεδομένων σε σύνολο εκπαίδευσης (*train set*) και στο σύνολο ακρίβειας (*test set*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The training set consists of the 0.80 of the initial dataset.\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size = 0.80)\n",
    "\n",
    "print(f\"- The training set consists of the {X_train_raw.shape[0]/features.shape[0]:.2f} of the initial dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα 3\n",
    "\n",
    "> *Πραγματοποιείστε προεπεξεργασία στα δεδομένα χρησιμοποιώντας τη μέθοδο TfidVectorizer της βιβλιοθήκης Scikit-Learn. Περισσότερες πληροφορίες για τη μέθοδο TfidVectorizer, που περιλαμβάνεται στις δηλώσεις του προγράμματος, μπορούν να βρεθούν [εδώ](#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Να σημειωθεί πως η μέθοδος TfidVectorizer της Scikit-Learn αφαιρεί και τα σημεία στίξης, καθώς επεξεργάζεται το dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα 4\n",
    "\n",
    "> *Εκπαιδεύεστε το μοντέλο logistic regression.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα 5\n",
    "\n",
    "> *Υπολογίστε την ακρίβειά του πάνω στο test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968609865470852"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_2_Logistic_Regression).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
